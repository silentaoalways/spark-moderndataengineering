default {

  appName = "spark-kafka-coffee-orders-consumer-app"

  spark {
    settings {
        "spark.master" = "local[*]"
        "spark.sql.session.timeZone" = "UTC"
        "spark.sql.warehouse.dir" = "s3a://com.coffeeco.data/warehouse"
        "spark.app.checkpoint.location" = "s3a://com.coffeeco.data/apps/spark-kafka-coffee-orders-app/1.0.0/"

        "spark.sql.streaming.kafka.useDeprecatedOffsetFetching" = "true"
        "spark.app.source.format" = "kafka"
        "spark.app.source.option.subscribe" = "com.coffeeco.coffee.v1.orders"
        "spark.app.source.option.kafka.bootstrap.servers" = "kafka_0:9092,kafka_1:9092,kafka_2:9092"
        "spark.app.source.option.startingOffsets" = "earliest"
        "spark.app.source.option.includeHeaders" = "false"
        "spark.app.sink.format" = "parquet"
        "spark.app.sink.queryName" = "coffee_orders_consumer"
        "spark.app.sink.option.checkpointLocation" = "s3a://com.coffeeco.data/apps/spark-kafka-coffee-orders-app/1.0.0/"
        "spark.app.sink.option.path" = "s3a://com.coffeeco.data/warehouse/silver/coffee_orders"
        "spark.app.sink.output.tableName" = "silver.coffee_orders"
        "spark.app.stream.trigger.enabled" = "true"
        "spark.app.stream.trigger.type" = "once"
        "spark.app.stream.output.mode" = " append"
        "spark.app.stream.processing.interval" = "30 seconds"

        "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version" = "2"
        "spark.hadoop.fs.s3a.impl" = "org.apache.hadoop.fs.s3a.S3AFileSystem"
        "spark.hadoop.fs.s3a.endpoint" = "http://minio:9000"
        "spark.hadoop.fs.s3a.connection.ssl.enabled" = "false"
        "spark.hadoop.fs.s3a.access.key" = "minio"
        "spark.hadoop.fs.s3a.secret.key" = "minio_admin"
        "spark.hadoop.fs.s3a.path.style.access" = "true"
        "spark.hadoop.fs.s3a.block.size" = "512M"

        "spark.sql.catalogImplementation" = "hive"
        "spark.sql.hive.metastore.version" = "2.3.7"
        "spark.sql.hive.metastore.jars" = "builtin"
        "spark.sql.hive.metastore.sharedPrefixes" = "org.mariadb.jdbc,com.mysql.cj.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,oracle.jdbc"
        "spark.sql.hive.metastore.schema.verification" = "true"
        "spark.sql.hive.metastore.schema.verification.record.version" = "true"

    }
  }

}