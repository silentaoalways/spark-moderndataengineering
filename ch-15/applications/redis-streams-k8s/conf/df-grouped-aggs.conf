default {
  appName = "spark-untyped-streaming-aggs-app"
  spark {
    settings {
        "spark.master" = "local[*]"
        "spark.sql.session.timeZone" = "UTC"

        # Configuring the DataSource (DataStreamReader)
        "spark.redis.host" = "redis"
        "spark.redis.port" = "6379"
        "spark.app.source.format" = "redis" # source format
        "spark.app.source.options.stream.keys" = "com:coffeeco:coffee:v1:orders" # the source redis stream
        "spark.app.source.options.stream.read.batch.size" = "100" #take up to 100 records per batch
        "spark.app.source.options.stream.read.block" = "1000" #wait up to 1 second while fetching new data

        # Configuring the Windowing / Watermark Operations
        "spark.app.groupBy.window.timestamp.column" = "timestamp"
        "spark.app.groupBy.window.duration" = "5 minutes"
        "spark.app.groupBy.window.slide.duration" = "5 minutes"
        "spark.app.groupBy.window.start.time" = "0 seconds"
        "spark.app.source.watermark.duration" = "5 minutes"

        # Configure the DataSink (DataStreamWriter)
        "spark.app.sink.format" = "parquet"
        "spark.app.sink.queryName" = "coffee_orders_aggs"
        "spark.app.sink.trigger.enabled" = "true"
        "spark.app.sink.trigger.type" = "process" # Once
        "spark.app.sink.processing.interval" = "30 seconds"
        "spark.app.sink.outputMode" = "append"
        "spark.app.sink.options.checkpointLocation" = "s3a://com.coffeeco.data/apps/spark-redis-streams-app/1.0.0"
        "spark.app.sink.options.path" = "s3a://com.coffeeco.data/warehouse/silver/coffee_order_aggs"
        "spark.app.sink.output.tableName" = "silver.coffee_order_aggs"
    }
  }
}